This is a custom feedforward Neural Net made without any ML libraries like PyTorch or Tensorflow. It's just linear algebra and calculus with NumPy.
Right now the repository includes the MNIST digits dataset and the folder digits_set contains the weights of a network that is trained on them
Network has 3 layers, first 2 are ReLU and final layer is softmax. Uses mean squared error for cost function.
